{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskGIT Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08mgRBhR4ECy",
    "outputId": "7ed19cc0-133e-4f12-c09a-2b9b60d82a3d"
   },
   "outputs": [],
   "source": [
    "is_colab = True\n",
    "if is_colab:\n",
    "    !git clone https://github.com/valeoai/Halton-MaskGIT.git\n",
    "    %cd Halton-MaskGIT\n",
    "    %pip install omegaconf>=2.0.0 einops>=0.3.0 webdataset>=2.0 huggingface_hub clean-fid torch-fidelity torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n74lvYYs5xY0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Utils.utils import load_args_from_file\n",
    "from Utils.viz import show_images_grid\n",
    "from Trainer.cls_trainer import MaskGIT\n",
    "from Sampler.halton_sampler import HaltonSampler\n",
    "from Sampler.confidence_sampler import ConfidenceSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskGIT initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zq-X-wgJ6APk",
    "outputId": "0a2c3eaf-8524-4d80-d290-2db0ed4fc9ce"
   },
   "outputs": [],
   "source": [
    "config_path = \"Config/base_cls2img.yaml\"        # Path to your config file\n",
    "args = load_args_from_file(config_path)\n",
    "args.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Overide the args parameters here to selec a different network\n",
    "args.vit_size = \"large\"   # \"tiny\", \"small\", \"base\", \"large\"\n",
    "args.img_size = 384       # 256 or 384\n",
    "args.compile = False      # compile is faster\n",
    "args.dtype = \"float32\"    # bfloat16 is faster \n",
    "args.resume = True\n",
    "args.vit_folder = f\"./saved_networks/ImageNet_{args.img_size}_{args.vit_size}.pth\"\n",
    "\n",
    "if is_colab:\n",
    "    hf_hub_download(repo_id=\"llvictorll/Halton-Maskgit\", filename=f\"ImageNet_{args.img_size}_{args.vit_size}.pth\", local_dir=\"./saved_networks\")\n",
    "    hf_hub_download(repo_id=\"FoundationVision/LlamaGen\",  filename=\"vq_ds16_c2i.pt\",  local_dir=\"./saved_networks\")\n",
    "    \n",
    "maskgit = MaskGIT(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2XIyDWH265bo"
   },
   "outputs": [],
   "source": [
    "def viz(x, nrow=10, pad=2, size=(18, 18)):\n",
    "    \"\"\"\n",
    "    Visualize a grid of images.\n",
    "\n",
    "    Args:\n",
    "        x (torch.Tensor): Input images to visualize.\n",
    "        nrow (int): Number of images in each row of the grid.\n",
    "        pad (int): Padding between the images in the grid.\n",
    "        size (tuple): Size of the visualization figure.\n",
    "\n",
    "    \"\"\"\n",
    "    nb_img = len(x)\n",
    "    min_norm = x.min(-1)[0].min(-1)[0].min(-1)[0].view(-1, 1, 1, 1)\n",
    "    max_norm = x.max(-1)[0].max(-1)[0].max(-1)[0].view(-1, 1, 1, 1)\n",
    "    x = (x - min_norm) / (max_norm - min_norm)\n",
    "\n",
    "    x = vutils.make_grid(x.float().cpu(), nrow=nrow, padding=pad, normalize=False)\n",
    "    plt.figure(figsize = size)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.permute(1, 2, 0))\n",
    "    plt.show()\n",
    "\n",
    "def decoding_viz(gen_code, mask, maskgit):\n",
    "    \"\"\"\n",
    "    Visualize the decoding process of generated images with associated masks.\n",
    "\n",
    "    Args:\n",
    "        gen_code (torch.Tensor): Generated code for decoding.\n",
    "        mask (torch.Tensor): Mask used for decoding.\n",
    "        maskgit (MaskGIT): MaskGIT instance.\n",
    "    \"\"\"\n",
    "    start = torch.FloatTensor([1, 1, 1]).view(1, 3, 1, 1).expand(1, 3, maskgit.input_size, maskgit.input_size) * 0.8\n",
    "    end = torch.FloatTensor([0.01953125, 0.30078125, 0.08203125]).view(1, 3, 1, 1).expand(1, 3, maskgit.input_size, maskgit.input_size) * 1.4\n",
    "    code = torch.stack((gen_code), dim=0).squeeze()\n",
    "    mask = torch.stack((mask), dim=0).view(-1, 1, maskgit.input_size, maskgit.input_size).cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x = maskgit.ae.decode_code(torch.clamp(code, 0, maskgit.args.mask_value))\n",
    "\n",
    "    binary_mask = (1-mask) * start + mask * end\n",
    "    binary_mask = vutils.make_grid(binary_mask, nrow=len(gen_code), padding=1, pad_value=0.4, normalize=False)\n",
    "    binary_mask = binary_mask.permute(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize = (18, 2))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.pcolormesh(binary_mask, edgecolors='w', linewidth=.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    viz(x, nrow=len(gen_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MaskGIT Sampling With the Halton Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_temp_min = 1.1   # Minimum softmax temperature for sampling.\n",
    "sm_temp_max = 1.1   # Maximum softmax temperature for sampling.\n",
    "top_k=-1            # If > 0, applies top-k sampling for token selection. \n",
    "temp_pow = 1        # Exponent for temperature scheduling.\n",
    "w=2                 # CFG weight\n",
    "sched_pow=2         # Power factor for the progressive unmasking schedule.\n",
    "step=32             # Number of steps to sample an image\n",
    "temp_warmup=1       # Number of initial steps where temperature is reduced.\n",
    "randomize=True      # If True, applies random shifts to the Halton sequence for diverse sampling.\n",
    "\n",
    "sampler = HaltonSampler(sm_temp_min=sm_temp_min, sm_temp_max=sm_temp_max, temp_pow=temp_pow, temp_warmup=temp_warmup, w=w, sched_pow=sched_pow, step=step, randomize=randomize, top_k=top_k)\n",
    "# goldfish, chicken, tiger cat, hourglass, ship, dog, race car, airliner, teddy bear\n",
    "labels = torch.LongTensor([1, 7, 282, 604, 724, 179, 681, 850]).to(args.device)\n",
    "\n",
    "# Generate sample\n",
    "gen_sample, gen_code, l_mask = sampler(maskgit, nb_sample=len(labels), labels=labels)\n",
    "viz(gen_sample, nrow=10, size=(18, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "id": "Dlyqve8b7CF8",
    "outputId": "868a2131-7780-4757-c637-622885dcf178",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_class = 8\n",
    "nb_sample = 2\n",
    "nb_row = 8\n",
    "# Generate all ImageNet Classes\n",
    "for l in range(0, 1000, nb_class):\n",
    "    labels = [l+i for i in range(nb_class)] * nb_sample\n",
    "    labels = torch.LongTensor(labels).to(args.device)\n",
    "    # Generate sample\n",
    "    gen_sample, gen_code, l_mask = sampler(maskgit, nb_sample=len(labels), labels=labels)\n",
    "    x = viz(gen_sample, nrow=nb_row, size=(18, 18))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
